import torch
from torch.utils.data import DataLoader, TensorDataset
import sys
import os
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from src.config import Config
from src.data_loader import create_federated_datasets, get_dataloaders
from src.model import get_model, get_poison_detector
from src.poison_detector import PoisonDetector
from src.federated_learning import FederatedLearning
import os

def print_header(text):
    print(f"\n{'='*60}")
    print(f"  {text}")
    print(f"{'='*60}\n")

def main():
    print_header("üè• APPRENTISSAGE F√âD√âR√â UNIQUEMENT (FL ONLY)")
    
    # 1. Chargement des donn√©es
    print("Chargement des datasets...")
    if not os.path.exists(Config.DATASET_PATH):
        print("‚ùå Dataset non trouv√©! Veuillez ex√©cuter l'option 1 du menu.")
        return

    hospital_datasets = create_federated_datasets(Config.DATASET_PATH)
    test_loader, _ = get_dataloaders(Config.DATASET_PATH)
    
    # 2. Chargement du mod√®le
    print("Initialisation du mod√®le Global (EfficientNet-V2)...")
    global_model = get_model(pretrained=True)
    
    # 3. Chargement du D√©tecteur (Autoencoder) existant
    print("\nüîç Verification du d√©tecteur de poison...")
    if os.path.exists("poison_detector.pth"):
        print("‚úì D√©tecteur trouv√© ('poison_detector.pth'). Chargement...")
        poison_detector = PoisonDetector(global_model)
        poison_detector.load_detector("poison_detector.pth")
        
        # 4. Filtrage (Gatekeeper)
        print_header("üßπ PRE-FILTRAGE DE TOUS LES H√îPITAUX")
        print("Nettoyage des donn√©es avant FL...")
        
        for i in range(len(hospital_datasets)):
            print(f"Tra√Ætement H√¥pital {i+1}...")
            loader = DataLoader(hospital_datasets[i], batch_size=Config.BATCH_SIZE, shuffle=False)
            
            # Utilisation du d√©tecteur
            # Note: filter_clean_data utilise le threshold calibr√© charg√©
            clean_data = poison_detector.filter_clean_data(loader)
            
            if len(clean_data) > 0:
                clean_imgs = torch.stack([x[0] for x in clean_data])
                clean_lbls = torch.stack([x[1] for x in clean_data])
                hospital_datasets[i] = TensorDataset(clean_imgs, clean_lbls)
                print(f"  ‚úì H√¥pital {i+1}: {len(hospital_datasets[i])} images valides.")
            else:
                print(f"  ‚ö†Ô∏è H√¥pital {i+1}: VIDE (Tout rejet√©)")
                
    else:
        print("‚ö†Ô∏è 'poison_detector.pth' NON TROUV√â.")
        print("‚ö†Ô∏è ATTENTION: L'apprentissage f√©d√©r√© va d√©marrer SANS filtrage de s√©curit√©.")
        print("   (Pour activer la s√©curit√©, lancez l'entra√Ænement complet une fois)")
        
    # 5. Apprentissage F√©d√©r√©
    print_header("üöÄ D√âMARRAGE DE L'APPRENTISSAGE F√âD√âR√â")
    fl_system = FederatedLearning(global_model)
    
    # Ex√©cution
    global_model = fl_system.federated_training(hospital_datasets)
    
    # 6. √âvaluation
    print_header("üìä √âVALUATION FINALE")
    accuracy = fl_system.evaluate_global_model(test_loader)
    
    # 7. Sauvegarde
    fl_system.save_global_model("global_model_final.pth")
    print("\n‚úì Termin√©.")

if __name__ == "__main__":
    main()
